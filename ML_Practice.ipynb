{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the matplotlib plotted graph within notebook lines.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "# pandas:Data framework library for Python\n",
    "# sklearn: Library to perform machine learning tasks\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import re\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn \n",
    "import sklearn.datasets\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gzip: 20news-19997.tar already exists;\tnot overwritten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# extract data\n",
    "#!gzip -d -k 20news-19997.tar.gz\n",
    "\n",
    "#!tar -xf 20news-19997.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "!ls 20_newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFilesDirectory(datapath='20_newsgroups'):\n",
    "    # create file directory for all files\n",
    "    files = []\n",
    "    for (path, dirnames, filenames) in os.walk(datapath):\n",
    "        files.extend(os.path.join(path, name) for name in filenames)\n",
    "    # putting file directories into pandas dataframe\n",
    "    directorydf= pd.DataFrame(files)\n",
    "    directorydf.columns = ['Directories']\n",
    "    return directorydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directorydf = getFilesDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_target (d):\n",
    "    if d.find(\"alt.atheism\") > 0 :\n",
    "      return 0\n",
    "    if d.find(\"comp.graphics\") > 0:\n",
    "      return 1\n",
    "    if d.find(\"comp.os.ms-windows.misc\") > 0:\n",
    "      return 2\n",
    "    if d.find(\"comp.sys.ibm.pc.hardware\") > 0:\n",
    "      return 3\n",
    "    if d.find(\"comp.sys.mac.hardware\") > 0:\n",
    "      return 4\n",
    "    if d.find(\"comp.windows.x\") > 0:\n",
    "      return 5\n",
    "    if d.find(\"misc.forsale\") > 0:\n",
    "      return 6\n",
    "    if d.find(\"rec.autos\") > 0:\n",
    "      return 7\n",
    "    if d.find(\"rec.motorcycles\") > 0:\n",
    "      return 8\n",
    "    if d.find(\"rec.sport.baseball\") > 0:\n",
    "      return 9\n",
    "    if d.find(\"rec.sport.hockey\") > 0:\n",
    "      return 10\n",
    "    if d.find(\"sci.crypt\") > 0:\n",
    "      return 11\n",
    "    if d.find(\"sci.electronics\") > 0:\n",
    "      return 12\n",
    "    if d.find(\"sci.med\") > 0:\n",
    "      return 13\n",
    "    if d.find(\"sci.space\") > 0:\n",
    "      return 14\n",
    "    if d.find(\"soc.religion.christian\") > 0:\n",
    "      return 15\n",
    "    if d.find(\"talk.politics.guns\") > 0:\n",
    "      return 16\n",
    "    if d.find(\"talk.politics.mideast\") > 0:\n",
    "      return 17\n",
    "    if d.find(\"talk.politics.misc\") > 0:\n",
    "      return 18\n",
    "    if d.find(\"talk.religion.misc\") > 0:\n",
    "      return 19\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Directories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20_newsgroups\\alt.atheism\\49960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20_newsgroups\\alt.atheism\\51060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20_newsgroups\\alt.atheism\\51119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20_newsgroups\\alt.atheism\\51120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20_newsgroups\\alt.atheism\\51121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Directories\n",
       "0  20_newsgroups\\alt.atheism\\49960\n",
       "1  20_newsgroups\\alt.atheism\\51060\n",
       "2  20_newsgroups\\alt.atheism\\51119\n",
       "3  20_newsgroups\\alt.atheism\\51120\n",
       "4  20_newsgroups\\alt.atheism\\51121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting file directories into pandas dataframw\n",
    "directorydf.columns = ['Directories']\n",
    "directorydf.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataPreprocessor(k, fs, encode, directorydf, size=None):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "        k: int. number of features to use\n",
    "        fs: string. From ['tf', 'mi']\n",
    "        encode: string. From ['tf', 'boolean']\n",
    "        drectorydf: Dataframe. It is given, see above support functions\n",
    "        size: int. Sample size. Default should be the data size.\n",
    "    OUTPUT\n",
    "        data: Dataframe. preprocessed data\n",
    "    \n",
    "    ps: 'tf' means term frequency, 'mi' means mutual information\n",
    "    \"\"\"\n",
    "    \n",
    "    ########### your code goes here ###########\n",
    "    nltk.download('stopwords')\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    import codecs\n",
    "    counter = Counter()\n",
    "    # Open the files and count the word frequency in each file in a loop and update the counter after finished processing a file\n",
    "    for rownum, row in enumerate(directorydf.itertuples()):\n",
    "        with codecs.open(row.Directories,\"r\" ,encoding='utf-8', errors='ignore') as myfile:\n",
    "            counter.update([word.lower() for word in re.findall(r'\\w+', myfile.read())if word not in stopwords.words('english')])\n",
    "        if (rownum % 1000 == 0):\n",
    "            print(\"processed %d files\" % (rownum+1))\n",
    "        if (rownum == size):\n",
    "            break\n",
    "            \n",
    "    topk = counter.most_common(k)\n",
    "            \n",
    "    np = []\n",
    "    if encode == 'boolean':\n",
    "    # now we had top k words, count the frequecy (binary) of these words in individual file\n",
    "        for rownum, row in enumerate(directorydf.itertuples()):\n",
    "            with codecs.open(row.Directories,\"r\" ,encoding='utf-8', errors='ignore') as myfile:\n",
    "                tempCounter = Counter([word for word in re.findall(r'\\w+', myfile.read())])\n",
    "                # if the word appears in the doc, then 1, else \n",
    "                topkinDoc = [1 if tempCounter[word] > 0 else 0 for (word,wordCount) in topk]\n",
    "                # create a list for top k words with encoded target and its label\n",
    "                np.append(topkinDoc+[label_target(row.Directories)])\n",
    "                if (rownum % 1000 == 0):\n",
    "                    print(\"processed %d files\" % (rownum+1))\n",
    "                if (rownum == size):\n",
    "                    break\n",
    "    else:\n",
    "        for rownum, row in enumerate(directorydf.itertuples()):\n",
    "            with codecs.open(row.Directories,\"r\" ,encoding='utf-8', errors='ignore') as myfile:\n",
    "                tempCounter = Counter([word for word in re.findall(r'\\w+', myfile.read())])\n",
    "                # if the word appears in the doc, then 1, else \n",
    "                topkinDoc = [tempCounter[word] if tempCounter[word] > 0 else 0 for (word,wordCount) in topk]\n",
    "                # create a list for top k words with encoded target and its label\n",
    "                np.append(topkinDoc+[label_target(row.Directories)])\n",
    "                if (rownum % 1000 == 0):\n",
    "                    print(\"processed %d files\" % (rownum+1))\n",
    "                if (rownum == size):\n",
    "                    break\n",
    "            \n",
    "                \n",
    "    data = pd.DataFrame(np)\n",
    "    dfName = []\n",
    "    for c in topk:\n",
    "        dfName.append(c[0])\n",
    "    dfName\n",
    "    data.columns = dfName+['target']\n",
    "    ###########         end         ###########\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "processed 1 files\n",
      "processed 1001 files\n",
      "processed 2001 files\n",
      "processed 1 files\n",
      "processed 1001 files\n",
      "processed 2001 files\n"
     ]
    }
   ],
   "source": [
    "#Might get back to this function to make it more efficient\n",
    "data = dataPreprocessor(k=50, fs='tf', encode='tf', directorydf=directorydf, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edu</th>\n",
       "      <th>i</th>\n",
       "      <th>cmu</th>\n",
       "      <th>com</th>\n",
       "      <th>cs</th>\n",
       "      <th>news</th>\n",
       "      <th>srv</th>\n",
       "      <th>graphics</th>\n",
       "      <th>the</th>\n",
       "      <th>net</th>\n",
       "      <th>...</th>\n",
       "      <th>ans</th>\n",
       "      <th>reston</th>\n",
       "      <th>howland</th>\n",
       "      <th>god</th>\n",
       "      <th>people</th>\n",
       "      <th>cc</th>\n",
       "      <th>posting</th>\n",
       "      <th>this</th>\n",
       "      <th>university</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edu  i  cmu  com  cs  news  srv  graphics  the  net   ...    ans  reston  \\\n",
       "0   10  1    5    1   3     4    3         0   63    1   ...      0       0   \n",
       "1    5  0    4    1   3     3    3         0  161    1   ...      1       1   \n",
       "2    7  0    3    3   4     2    2         0   31    1   ...      1       1   \n",
       "3    6  0    4    1   3     1    3         0    9    1   ...      1       1   \n",
       "4    4  0    4    8   3     0    3         0    2    1   ...      1       1   \n",
       "\n",
       "   howland  god  people  cc  posting  this  university  target  \n",
       "0        0    3       5   0        0     4           0       0  \n",
       "1        1    1      21   0        1    12           0       0  \n",
       "2        1    0       1   0        0     2           0       0  \n",
       "3        1    0       0   0        0     2           2       0  \n",
       "4        1    0       0   0        0     1           0       0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confidence Interval Function\n",
    "import scipy.stats\n",
    "from math import sqrt\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    mu,sd = np.mean(a),np.std(a)\n",
    "    z = stats.t.ppf(confidence, n)\n",
    "    h=z*sd/sqrt(n)\n",
    "    return mu, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomSplitCI(data, clf, num_run, **params):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "        data: 2D numpy array. Pre-processed data\n",
    "        clf: string. Name of the classifier from ['LR', 'SVM', 'NB']\n",
    "        num_run: int. How many times you want to run for random evaluation?\n",
    "        params: string->real. Hyper-parameter of classifier. PS: c=1.0, r=0.01\n",
    "    \n",
    "    OUTPUT\n",
    "        train_scores: list. Results of trails\n",
    "        test_scores: list. Results of trails\n",
    "        train_mean: scalar. Average accuracy\n",
    "        test_mean: scalar. Average accuracy\n",
    "        train_ci: scalar. Confidence Interval\n",
    "        test_ci: scalar. Confidence Interval\n",
    "    \"\"\"\n",
    "    \n",
    "    ########### your code goes here ###########\n",
    "    if clf == 'LR':\n",
    "        clf = LogisticRegression(C=params[\"c\"])#add if statement to account for SVM and NB\n",
    "    else:\n",
    "        clf = GaussianNB()\n",
    "    #clf.set_params(**params)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    \n",
    "    for i in range (0,num_run):\n",
    "        np.random.permutation(data)\n",
    "        features = data.iloc[:,:data.columns.get_loc(\"target\")-1].as_matrix()\n",
    "        target = data['target'].as_matrix()\n",
    "        features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3)\n",
    "        clfModel = clf.fit(features_train, target_train)\n",
    "        target_pred = clfModel.predict(features_test)\n",
    "        train_pred = clfModel.predict(features_train)\n",
    "        #pd.DataFrame(metrics.confusion_matrix(target_test, target_pred), columns=labels, index=labels)\n",
    "        test_scores.append(metrics.accuracy_score(target_test, target_pred))\n",
    "        train_scores.append(metrics.accuracy_score(target_train, train_pred))\n",
    "        #print(test_scores)\n",
    "    train_mean, train_ci = mean_confidence_interval(train_scores)\n",
    "    test_mean, test_ci = mean_confidence_interval(test_scores)\n",
    "    ###########         end         ###########\n",
    "    return train_scores, test_scores, train_mean, test_mean, train_ci, test_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train    \n",
      "Result of trails:[1.0, 1.0, 0.99928571428571433, 0.99928571428571433, 1.0, 1.0, 0.99928571428571433, 0.99928571428571433, 1.0, 0.99928571428571433]     \n",
      "Average Accuracy: 0.9996428571428572     \n",
      "Confidence Interval: 0.00020469661852098937\n",
      "\n",
      "Test    \n",
      "Result of trails:[0.99833610648918469, 0.99833610648918469, 1.0, 1.0, 0.99833610648918469, 0.99833610648918469, 1.0, 1.0, 0.99833610648918469, 1.0]     \n",
      "Average Accuracy: 0.9991680532445922     \n",
      "Confidence Interval: 0.00047683072534010604\n"
     ]
    }
   ],
   "source": [
    "train_scores,test_scores,train_mean,test_mean,train_ci,test_ci = randomSplitCI(data, 'LR', 10, c=1.0)\n",
    "print(\"Train\\\n",
    "    \\nResult of trails:{0} \\\n",
    "    \\nAverage Accuracy: {1} \\\n",
    "    \\nConfidence Interval: {2}\\n\".format(train_scores, train_mean, train_ci)\n",
    "    )\n",
    "print(\"Test\\\n",
    "    \\nResult of trails:{0} \\\n",
    "    \\nAverage Accuracy: {1} \\\n",
    "    \\nConfidence Interval: {2}\".format(test_scores, test_mean, test_ci)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomSplitCM(data, clf, num_run, **params):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "        data: Dataframe. Pre-processed data\n",
    "        clf: string. Name of the classifier from ['LR', 'SVM', 'NB']\n",
    "        params: string->real. Hyper-parameter of classifier. PS: c=1.0, r=0.01\n",
    "    \n",
    "    OUTPUT\n",
    "        cm: pandas.DataFrame. Confusion Matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ########### your code goes here ###########\n",
    "    if clf == 'LR':\n",
    "        clf = LogisticRegression(C=params[\"c\"])\n",
    "    else:\n",
    "        clf = GaussianNB()\n",
    "    #clf.set_params(**params)\n",
    "    cms = {}\n",
    "    #labels = np.unique(data['label'].apply(lambda x: x.split(\"\\\\\")[1]))\n",
    "    for i in range(0,num_run):\n",
    "        np.random.permutation(data)\n",
    "        features = data.iloc[:,:data.columns.get_loc(\"target\")-1].as_matrix()\n",
    "        target = data['target'].as_matrix()\n",
    "        features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3)\n",
    "        #vfunc = np.vectorize(lambda x: x.split(\"\\\\\")[1])\n",
    "        labels = np.unique(target_test)\n",
    "        clfModel = clf.fit(features_train, target_train)\n",
    "        target_pred = clfModel.predict(features_test)\n",
    "        #print(target_test.shape)\n",
    "        #print(target_pred.shape)\n",
    "        #print(labels.shape)\n",
    "        #train_pred = clfModel.predict(features_train)\n",
    "        cms[i] = pd.DataFrame(metrics.confusion_matrix(target_test, target_pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    pl = pd.Panel(cms)\n",
    "    cm = pl.sum(axis=0) #Sum the confusion matrices to get one view of how well the classifiers perform\n",
    "    cm\n",
    "    \n",
    "    ###########         end         ###########\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cm = randomSplitCM(data, 'LR', 10, c=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3000     0\n",
       "1     0  3010"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22c3e383588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD8CAYAAACrbmW5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQKgAWspwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c3e3f7da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
